{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfo3zAxouGOkq4hhns6qfI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mazinkamal134/DS_MRP_2024/blob/main/TensiStrength/3_TensiStrength_Combine_%26_Finalize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please note:\n",
        "- Use this notebook to combine the files generated by the previous step in this pipeline.\n",
        "- Also use it to rescale the relax/stress score and add a combined score."
      ],
      "metadata": {
        "id": "HeBOQ06JbP3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "import html\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "B1gaIhokbQ0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Params"
      ],
      "metadata": {
        "id": "GCeUgpBLcqlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensiStrenghtChunksDir = r\"/TensiStrenght/Chunks\"\n",
        "tensiStrenghtDir = r\"/TensiStrenght/\"\n",
        "numberOfFiles = 5\n",
        "disorder = \"anxiety\" # [\"depression\", \"ptsd\"]"
      ],
      "metadata": {
        "id": "KtZnjNwicsSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the files chunks & combine"
      ],
      "metadata": {
        "id": "VBAxgcLWcmD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read one file to infer the dataframe schema\n",
        "fileName = f\"{disorder}TweetsDfWithTensiStrengthScore_0.pickle\"\n",
        "filePath = os.path.join(tensiStrenghtChunksDir, fileName)\n",
        "with open(filePath, 'rb') as f:\n",
        "    df = pickle.load(f)\n",
        "containerDf = df.copy(deep = True)\n",
        "containerDf.drop(containerDf.index, inplace = True)\n",
        "toInvestigateDf = df.copy(deep = True)\n",
        "toInvestigateDf.drop(toInvestigateDf.index, inplace = True)\n",
        "del df\n",
        "print(\"Shape:\", toInvestigateDf.shape)"
      ],
      "metadata": {
        "id": "cskMnWUHcpsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop throguh the files, read and combine\n",
        "for i in range(numberOfFiles):\n",
        "    fileName = os.path.join(tensiStrenghtChunksDir, f\"{disorder}TweetsDfWithTensiStrengthScore_{i}.pickle\")\n",
        "    print(\"Processing:\", fileName)\n",
        "    with open(fileName, 'rb') as f:\n",
        "        fullDf = pickle.load(f)\n",
        "    # Add to the main Df\n",
        "    containerDf = pd.concat([containerDf, fullDf[fullDf.relaxScore.notna()]])\n",
        "    toInvestigateDf = pd.concat([toInvestigateDf, fullDf[fullDf.relaxScore.isna()]])\n",
        "    print(\"Done processing:\", fileName)\n",
        "\n",
        "print(\"Shape of scored:\", containerDf.shape)\n",
        "print(\"Shape of not scored:\", toInvestigateDf.shape)\n",
        "containerDf.sample()"
      ],
      "metadata": {
        "id": "W6YeDFybdVRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finalize\n",
        "\n",
        "\n",
        "*   Fix the data types\n",
        "*   Adjust the stress scores (change the scale to 0 - 4)\n",
        "*   Add a combined score using the relax and sterss scores\n",
        "\n"
      ],
      "metadata": {
        "id": "rF7Lxo0gesPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the data types\n",
        "containerDf[\"relaxScore\"] = containerDf[\"relaxScore\"].astype(\"int64\")\n",
        "containerDf[\"stressScore\"] = containerDf[\"stressScore\"].astype(\"int64\")\n",
        "\n",
        "# Create new column using the relax/stress score\n",
        "containerDf[\"relaxScoreAltered\"] = containerDf[\"relaxScore\"].apply(lambda x: x - 1)\n",
        "containerDf[\"stressScoreAltered\"] = containerDf[\"stressScore\"].apply(lambda x: abs(x + 1))\n",
        "\n",
        "# Use min max scaler on the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# Scale\n",
        "containerDf[\"scaledScore\"] = scaler.fit_transform(np.array(containerDf[\"relaxScore\"] + containerDf[\"stressScore\"]).reshape(-1, 1))\n",
        "# Invert the scores\n",
        "containerDf[\"scaledScore\"] = 1 - containerDf[\"scaledScore\"]\n",
        "\n",
        "# Rename some of the columns\n",
        "renamed = {\"relaxScore\": \"relax_score_org\",\n",
        "          \"stressScore\": \"stress_score_org\",\n",
        "          \"scaledScore\": \"combined_score\",\n",
        "          \"stressScoreAltered\": \"stress_score\",\n",
        "          \"relaxScoreAltered\": \"relax_score\"\n",
        "          }\n",
        "containerDf.rename(columns = renamed, inplace = True)\n",
        "# Organize the columns\n",
        "cols = [\"id\", \"tweet_type\", \"referenced_tweet_type\", \"created_at\", \"lang\", \"disorder\", \"group\", \"author_id\", \"text\", \"cleaned_text\", \"retweet_count\", \"reply_count\", \"like_count\", \"quote_count\", \"source\", \"group\", \"relax_score_org\", \"stress_score_org\", \"relax_score\", \"stress_score\", \"combined_score\"]\n",
        "containerDf = containerDf[cols]\n",
        "\n",
        "# Check\n",
        "containerDf.sample()"
      ],
      "metadata": {
        "id": "N-BcDXFuexOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save"
      ],
      "metadata": {
        "id": "b7sqs6RJgBOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to pickle\n",
        "fileName = f\"{disorder}FullWithTensiScore.pickle\"\n",
        "containerDf.to_pickle(os.path.join(tensiStrenghtDir, fileName))"
      ],
      "metadata": {
        "id": "Y9viLDn9gCJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next step is to use the disorder final files to update the master dataset on the main data pipeline"
      ],
      "metadata": {
        "id": "1bAgFYaLgnOW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfs3uDvKgur6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}