{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mazinkamal134/DS_MRP_2024/blob/main/Master_Dataset_Processing_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will generate the master tweet dataset, from which all individual disorder datasets could be created. Following the below steps:\n",
        "- Ingest the tweets (control and treatment)\n",
        "- Add the diagnosis dates and treatment dates\n",
        "- Add the music sessions\n",
        "- Add the TensiStrengh stress scores\n",
        "- Add the user info\n",
        "- Add the demographic info\n",
        "\n",
        "It depends on two other pipelines:\n",
        "- TensiStrength pipeline\n",
        "- Demographic inference pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "AFUo5ferwF7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "ZCYA0RVxwGx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1fGXpDkwJXa",
        "outputId": "1ef70e6b-7ed5-434d-a690-cf4ca0253637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Global Params"
      ],
      "metadata": {
        "id": "QcN6jYCBJYtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweetsDir = \"/content/drive/MyDrive/Master-2024/MRP/Data/Tweets\"\n",
        "datesDir = \"/content/drive/MyDrive/Master-2024/MRP/Data/Tweets/Treatment Dates\"\n",
        "tensiStrenghtDir = \"/content/drive/MyDrive/Master-2024/MRP/Data/TensiStrength\"\n",
        "demographicsDir = \"/content/drive/MyDrive/Master-2024/MRP/Data/Demographics\"\n",
        "authorsDir = \"/content/drive/MyDrive/Master-2024/MRP/Data/Authors\"\n",
        "musicDir = \"/content/drive/MyDrive/Master-2024/MRP/Data/Music\"\n",
        "anxietyStrataDir = \"/content/drive/MyDrive/Master-2024/MRP/Data/Authors/PSM/anxiety/Stratums\"\n",
        "depressionStrataDir = \"/content/drive/MyDrive/Master-2024/MRP/Data/Authors/PSM/depression/Stratums\"\n",
        "ptsdStrataDir = \"/content/drive/MyDrive/Master-2024/MRP/Data/Authors/PSM/ptsd/Stratums\""
      ],
      "metadata": {
        "id": "WdkH_OM7wdiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read parquet file for modifications only, such as updating the demographic or Stress scores\n",
        "# Otherwise, skip this step and go through all other steps one by one\n",
        "\"\"\"\n",
        "fileName = os.path.join(tweetsDir, \"processedTweets.parquet\")\n",
        "tweetsDf = pd.read_parquet(fileName)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nGk1KHwrPCfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ingest the control tweets"
      ],
      "metadata": {
        "id": "c1Jp8HsqxFEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the control Tweets CSV file and pickle\n",
        "fileName = os.path.join(tweetsDir, \"control_tweets.csv\")\n",
        "controlTweetsDf = pd.read_csv(fileName)\n",
        "# Add the group\n",
        "controlTweetsDf[\"group\"] = 0\n",
        "print(\"Control Shape:\", controlTweetsDf.shape)"
      ],
      "metadata": {
        "id": "b5BF4JKPwaYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ingest the treatment tweets"
      ],
      "metadata": {
        "id": "bjMfRFtyxONM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the treatment Tweets CSV file and pickle\n",
        "fileName = os.path.join(tweetsDir, \"treatment_tweets.csv\")\n",
        "treatmentTweetsDf = pd.read_csv(fileName)\n",
        "# Add the group\n",
        "treatmentTweetsDf[\"group\"] = 1\n",
        "print(\"Treatment Shape:\", treatmentTweetsDf.shape)"
      ],
      "metadata": {
        "id": "Z2hrIFbnxLpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine control and treatment"
      ],
      "metadata": {
        "id": "eMTraK1qxbPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine\n",
        "tweetsDf = pd.concat([controlTweetsDf, treatmentTweetsDf])\n",
        "print(\"Shape combined:\", tweetsDf.shape)\n",
        "\n",
        "# Free up the menmory (only on Jupytor, no need on Google Colab with High-RAM)\n",
        "#del controlTweetsDf\n",
        "#del treatmentTweetsDf\n",
        "\n",
        "# Fix the data types\n",
        "tweetsDf[\"created_at\"] = pd.to_datetime(tweetsDf.created_at).dt.tz_convert(None)\n",
        "tweetsDf[\"author_id\"] = tweetsDf[\"author_id\"].astype(\"str\")\n",
        "\n",
        "# Reorder the columns\n",
        "cols = [\"id\", \"tweet_type\", \"referenced_tweet_type\", \"created_at\", \"lang\", \"disorder\", \"author_id\", \"text\", \"cleaned_text\", \"retweet_count\", \"reply_count\", \"like_count\", \"quote_count\", \"source\", \"group\"]\n",
        "tweetsDf = tweetsDf[cols]"
      ],
      "metadata": {
        "id": "7Mg8dRuUxgCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the diagnose dates\n"
      ],
      "metadata": {
        "id": "x6JjQgcexqFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosisDatesDf = tweetsDf[tweetsDf.tweet_type == \"diagnose\"].reset_index(drop = True)\n",
        "# Convert the created_at to date\n",
        "diagnosisDatesDf[\"created_at\"] = diagnosisDatesDf[\"created_at\"].dt.date\n",
        "# Keep only the author_id, created_at, and group, and rename created_at to diagnosis_date\n",
        "diagnosisDatesDf = diagnosisDatesDf[[\"author_id\", \"created_at\"]].rename(columns = {\"created_at\": \"diagnosis_date\"})\n",
        "# Select the tweet with the minimum created data for each author and remove others\n",
        "diagnosisDatesDf = diagnosisDatesDf.groupby(\"author_id\").diagnosis_date.min().reset_index()\n",
        "print (\"Diagnosis Dates Shape:\", diagnosisDatesDf.shape)\n",
        "diagnosisDatesDf.sample()"
      ],
      "metadata": {
        "id": "ySn8e30wxv1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Update the diagnosis dates for all"
      ],
      "metadata": {
        "id": "SwCyiyCfy7y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the diagnosis date to the main dataframe\n",
        "tweetsDf = tweetsDf.merge(diagnosisDatesDf, on = [\"author_id\"], how = \"left\")\n",
        "print(\"Shape after updating with diagnosis date:\", tweetsDf.shape)\n",
        "# Count the unmatched records\n",
        "print(\"Unmatched:\", tweetsDf[tweetsDf.diagnosis_date.isna()].shape[0])\n",
        "# Check\n",
        "tweetsDf.sample()"
      ],
      "metadata": {
        "id": "_IqCfq3QzGHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Populate the treatment dates"
      ],
      "metadata": {
        "id": "f25-d28y2CsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the anchor dates\n",
        "controlFilePath = os.path.join(datesDir, \"control_users_features_summary.json\")\n",
        "treatmentFilePath = os.path.join(datesDir, \"treatment_users_features_summary.json\")\n",
        "\n",
        "# Read the json data\n",
        "with open(controlFilePath, \"rb\") as f:\n",
        "    file = json.load(f)\n",
        "controlDf = pd.DataFrame(file).transpose().reset_index()\n",
        "controlDf[\"Group\"] = 0\n",
        "with open(treatmentFilePath, \"rb\") as f:\n",
        "    file = json.load(f)\n",
        "treatmentDf = pd.DataFrame(file).transpose().reset_index()\n",
        "treatmentDf[\"Group\"] = 1\n",
        "\n",
        "# Combine\n",
        "treatmentDatesDf = pd.concat([controlDf, treatmentDf], ignore_index = True)\n",
        "\n",
        "# Process\n",
        "treatmentDatesDf.rename(columns = {\"index\": \"author_id\", \"diagnose_date\": \"treatment_date\"}, inplace = True)\n",
        "\n",
        "# drop unnecessary columns\n",
        "colsToKeep = [\"author_id\", \"treatment_date\", \"Group\"]\n",
        "treatmentDatesDf = treatmentDatesDf[colsToKeep]\n",
        "\n",
        "# Fix the data types\n",
        "treatmentDatesDf[\"treatment_date\"] = pd.to_datetime(treatmentDatesDf[\"treatment_date\"])\n",
        "\n",
        "# Drop duplicates\n",
        "treatmentDatesDf.drop_duplicates()\n",
        "\n",
        "# Check\n",
        "print(\"Shape:\", treatmentDatesDf.shape)\n",
        "# Select the author with the minimum treatment date\n",
        "treatmentDatesDf = treatmentDatesDf.groupby([\"author_id\"]).treatment_date.min().reset_index()\n",
        "treatmentDatesDf.sample()"
      ],
      "metadata": {
        "id": "TX3x2nSzzaGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join the treatment dates with the main dataframe\n",
        "tweetsDf = tweetsDf.merge(treatmentDatesDf, on = [\"author_id\"], how = \"left\")\n",
        "print(\"Shape after adding the treatment dates\", tweetsDf.shape)\n",
        "# Check\n",
        "tweetsDf.sample()"
      ],
      "metadata": {
        "id": "Dr78D__Y2kG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add the music sessions"
      ],
      "metadata": {
        "id": "T6Fwx1dr3DtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest the music file\n",
        "musicFilePath = os.path.join(musicDir, \"music.csv\")\n",
        "musicDf = pd.read_csv(musicFilePath)\n",
        "# Fix the data types\n",
        "musicDf[\"created_at\"] = pd.to_datetime(musicDf[\"created_at\"]).dt.tz_convert(None)\n",
        "musicDf[\"author_id\"] = musicDf[\"author_id\"].astype(\"str\")\n",
        "# rename tweet_id to id\n",
        "musicDf.rename(columns = {\"tweet_id\": \"id\"}, inplace = True)\n",
        "# Keep only the tweet and music_id columns\n",
        "musicDf = musicDf[[\"id\", \"music_id\"]]\n",
        "# Drop duplicates\n",
        "musicDf.drop_duplicates(inplace = True)\n",
        "# Check\n",
        "print(\"Shape:\", musicDf.shape)\n",
        "musicDf.sample()\n",
        "# tweets with multiple music ids\n",
        "musicDf.groupby(\"id\").music_id.nunique().reset_index().query(\"music_id > 1\").shape"
      ],
      "metadata": {
        "id": "R9gHduyt3JGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the main dataframe by adding music_id\n",
        "tweetsDf = tweetsDf.merge(musicDf, on = [\"id\"], how = \"left\")\n",
        "print(\"Shape after adding the music sessions\", tweetsDf.shape)\n",
        "# Update the unmatched music_id with 0\n",
        "tweetsDf[\"music_id\"] = tweetsDf[\"music_id\"].fillna(0)\n",
        "# Check\n",
        "tweetsDf.sample()"
      ],
      "metadata": {
        "id": "QRqekjzX46_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the tweet type, set it to \"treatment\" wherever the music_id is not 0\n",
        "tweetsDf.loc[tweetsDf[\"music_id\"] != 0, \"tweet_type\"] = \"treatment\"\n",
        "# Check\n",
        "tweetsDf.sample()"
      ],
      "metadata": {
        "id": "fXSpkJJ3Plyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add Demographics\n",
        "Before running this part make sure the demographics pipeline was run and all 3 demographics files were created successfully"
      ],
      "metadata": {
        "id": "PvmftDlQJOv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the demographics user files\n",
        "ageDf = pd.read_pickle(os.path.join(demographicsDir, \"authorAge.pickle\"))\n",
        "genderDf = pd.read_pickle(os.path.join(demographicsDir, \"authorGender.pickle\"))\n",
        "eduLevelDf = pd.read_pickle(os.path.join(demographicsDir, \"authorEducationLevel.pickle\"))\n",
        "eduLevelDf.rename(columns = {\"ari_grade\": \"edu_level\"}, inplace = True)\n",
        "# Check\n",
        "print(\"Age df Shape:\", ageDf.shape)\n",
        "print(\"Gender df Shape:\", genderDf.shape)\n",
        "print(\"Education Level df Shape:\", eduLevelDf.shape)"
      ],
      "metadata": {
        "id": "pyvHYhgTJTho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the columns exist\n",
        "if set([\"age_group\", \"gender\", \"edu_level\"]).issubset(set(tweetsDf.columns)):\n",
        "  # drop & update\n",
        "  tweetsDf.drop([\"age_group\", \"gender\", \"edu_level\"], axis = 1, inplace = True)\n",
        "  # Merge the demographics data with the tweetsDf\n",
        "  tweetsDf = tweetsDf.merge(ageDf[[\"author_id\", \"age_group\"]], on = [\"author_id\"], how = \"left\")\n",
        "  tweetsDf = tweetsDf.merge(genderDf[[\"author_id\", \"gender\"]], on = [\"author_id\"], how = \"left\")\n",
        "  tweetsDf = tweetsDf.merge(eduLevelDf[[\"author_id\", \"edu_level\"]], on = [\"author_id\"], how = \"left\")\n",
        "else: # Update\n",
        "  # Merge the demographics data with the tweetsDf\n",
        "  tweetsDf = tweetsDf.merge(ageDf[[\"author_id\", \"age_group\"]], on = [\"author_id\"], how = \"left\")\n",
        "  tweetsDf = tweetsDf.merge(genderDf[[\"author_id\", \"gender\"]], on = [\"author_id\"], how = \"left\")\n",
        "  tweetsDf = tweetsDf.merge(eduLevelDf[[\"author_id\", \"edu_level\"]], on = [\"author_id\"], how = \"left\")\n",
        "# Check\n",
        "print(\"Shape after adding the demographics\", tweetsDf.shape)"
      ],
      "metadata": {
        "id": "nF9soOBSKMSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensiStrenght Score\n",
        "- Run the TensiStrenght Pipeline on timeline tweets with text\n",
        "- Make sure the TensiStrength pipleline generated the files successfully before running this part"
      ],
      "metadata": {
        "id": "DqH-yLzXORBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the tensiStrenght files (Depression)\n",
        "depressionWithTensiDf = pd.read_pickle(os.path.join(tensiStrenghtDir, \"depressionFullWithTensiScore.pickle\"))\n",
        "print(\"Shape:\", depressionWithTensiDf.shape)\n",
        "# Select the required columns only\n",
        "depressionWithTensiDf = depressionWithTensiDf[[\"id\", \"author_id\", \"relax_score_org\", \"stress_score_org\", \"relax_score\", \"stress_score\", \"combined_score\"]]\n",
        "\n",
        "# Read the tensiStrenght files (Anxiety)\n",
        "anxietyWithTensiDf = pd.read_pickle(os.path.join(tensiStrenghtDir, \"anxietyFullWithTensiScore.pickle\"))\n",
        "print(\"Shape:\", anxietyWithTensiDf.shape)\n",
        "# Select the required columns only\n",
        "anxietyWithTensiDf = anxietyWithTensiDf[[\"id\", \"author_id\", \"relax_score_org\", \"stress_score_org\", \"relax_score\", \"stress_score\", \"combined_score\"]]\n",
        "\n",
        "# Read the tensiStrenght files (PTSD)\n",
        "ptsdWithTensiDf = pd.read_pickle(os.path.join(tensiStrenghtDir, \"ptsdFullWithTensiScore.pickle\"))\n",
        "print(\"Shape:\", ptsdWithTensiDf.shape)\n",
        "# Select the required columns only\n",
        "ptsdWithTensiDf = ptsdWithTensiDf[[\"id\", \"author_id\", \"relax_score_org\", \"stress_score_org\", \"relax_score\", \"stress_score\", \"combined_score\"]]\n",
        "\n",
        "# Combine the anxiety, depression, and PTSD TensiStrenght dataframes and remove duplicates based on id\n",
        "tensiStrenghtDf = pd.concat([anxietyWithTensiDf, depressionWithTensiDf, ptsdWithTensiDf]) #, missingWithTensiDf\n",
        "tensiStrenghtDf.drop_duplicates(subset = [\"id\"], inplace = True)\n",
        "print(\"Tensi df Shape:\", tensiStrenghtDf.shape)\n",
        "\n",
        "# Merge with tweetsDf based on id\n",
        "cols = [\"id\", \"relax_score_org\", \"stress_score_org\", \"relax_score\", \"stress_score\", \"combined_score\"]\n",
        "# Check if the columns exist in the dataframe\n",
        "if set(cols).issubset(set(tweetsDf.columns)):\n",
        "  # drop\n",
        "  tweetsDf.drop([\"relax_score_org\", \"stress_score_org\", \"relax_score\", \"stress_score\", \"combined_score\"], axis = 1, inplace = True)\n",
        "else: # Update\n",
        "  tweetsDf = tweetsDf.merge(tensiStrenghtDf[cols], on = [\"id\"], how = \"left\")\n",
        "  print(\"Shape of tweets df after adding the tensiStrenght score\", tweetsDf.shape)"
      ],
      "metadata": {
        "id": "rtwIbCE2OUVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Validate"
      ],
      "metadata": {
        "id": "r5zoslYZoroE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find anxiety/depression/PTSD tweets with no score\n",
        "missingTensiDf = tweetsDf[(tweetsDf.disorder.isin([\"depression\", \"anxiety\", \"ptsd\"])) &\n",
        "(tweetsDf.combined_score.isna()) &\n",
        "(tweetsDf.lang == \"en\") &\n",
        "(tweetsDf.cleaned_text.notna())]\n",
        "\n",
        "missingCount = missingTensiDf.shape[0]\n",
        "print(\"Missing Tensi scores:\", missingCount)\n",
        "\n",
        "# Pickle the resulting dataframe\n",
        "if missingCount > 0:\n",
        "  fileName = os.path.join(tensiStrenghtDir, \"missingTensiDf.pickle\")\n",
        "  missingTensiDf.to_pickle(fileName)\n",
        "  # Report\n",
        "  print(\"Shape of the missing Tensi scores df:\", missingTensiDf.shape)\n",
        "  missingTensiDf.sample()"
      ],
      "metadata": {
        "id": "vH-vCzymQ0JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User/Authors Info"
      ],
      "metadata": {
        "id": "PIp383GULN9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Original List"
      ],
      "metadata": {
        "id": "Dlns5299LNCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "controlUsers = pd.read_csv(os.path.join(authorsDir, \"authors_control.csv\"))\n",
        "# Add the group column\n",
        "controlUsers[\"group\"] = 0\n",
        "print(\"Control users shape:\", controlUsers.shape)\n",
        "treatmentUsers = pd.read_csv(os.path.join(authorsDir, \"authors_treatment.csv\"))\n",
        "treatmentUsers[\"group\"] = 1\n",
        "print(\"Treatment users shape:\", treatmentUsers.shape)\n",
        "\n",
        "# Combine\n",
        "usersDf = pd.concat([controlUsers, treatmentUsers])\n",
        "\n",
        "# Remove the unnecessary columns\n",
        "usersDf.drop([\"anonymized_id\", \"matched_author_count\", \"matched_author_ids\", \"location\", \"username\"], axis = 1, inplace = True)\n",
        "\n",
        "# Fix the datatypes\n",
        "usersDf[\"created_at\"] = pd.to_datetime(usersDf[\"created_at\"]).dt.tz_localize(None)\n",
        "# find the account age\n",
        "usersDf[\"account_age\"] = (pd.to_datetime(\"today\") - usersDf[\"created_at\"]).dt.days/365.0\n",
        "# Fill na\n",
        "usersDf[\"account_age\"].fillna(0, inplace = True)\n",
        "toFill = [\"followers_count\", \"following_count\", \"tweet_count\"]\n",
        "# Fill and convert to int\n",
        "usersDf[toFill] = usersDf[toFill].fillna(0)\n",
        "usersDf[\"followers_count\"] = usersDf[\"followers_count\"].astype(\"int64\")\n",
        "usersDf[\"following_count\"] = usersDf[\"following_count\"].astype(\"int64\")\n",
        "usersDf[\"tweet_count\"] = usersDf[\"tweet_count\"].astype(\"int64\")\n",
        "\n",
        "# Fill the rest of columns with nothing\n",
        "usersDf.fillna(\"\", inplace = True)\n",
        "\n",
        "# find the length of the description field\n",
        "usersDf[\"description_len\"] = usersDf[\"description\"].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Reorganize the columns (get the disorder from the matching set)\n",
        "reOrg = ['id', 'created_at', \"account_age\", 'verified', 'name', 'description', \"description_len\", 'group', 'followers_count', 'following_count', 'tweet_count']\n",
        "usersDf = usersDf[reOrg]\n",
        "# Rename id to author_id\n",
        "usersDf.rename({\"id\":\"author_id\", \"created_at\": \"author_since\"}, axis = 1, inplace = True)\n",
        "# Change the author_id data type to str\n",
        "usersDf[\"author_id\"] = usersDf[\"author_id\"].astype(\"str\")\n",
        "# Check\n",
        "print(\"Full dataset shape:\", usersDf.shape)"
      ],
      "metadata": {
        "id": "Od5BUIYRLQkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PSM\n",
        "using the output of the propensity score matching for more refined results"
      ],
      "metadata": {
        "id": "LYGhGBy-LR12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest the matching datasets\n",
        "disorders = {\"anxiety\": anxietyStrataDir, \"depression\": depressionStrataDir, \"ptsd\": ptsdStrataDir}\n",
        "matchingDfs = []\n",
        "for disorder, strataDir in disorders.items():\n",
        "  files = sorted(os.listdir(strataDir))\n",
        "  firstFileName = files[0]\n",
        "  # read the json file using json\n",
        "  with open(os.path.join(strataDir, firstFileName)) as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  disorderDf = pd.DataFrame(data)\n",
        "  disorderDf[\"stratum\"] = 0\n",
        "\n",
        "  for i, fileName in enumerate([f for f in files if f != firstFileName]):\n",
        "      # read the json file using json\n",
        "      with open(os.path.join(strataDir, fileName)) as f:\n",
        "        data = json.load(f)\n",
        "      df = pd.DataFrame(data)\n",
        "      df[\"stratum\"] = i + 1\n",
        "      disorderDf = pd.concat([disorderDf, df])\n",
        "\n",
        "  matchingDfs.append(disorderDf)\n",
        "\n",
        "# Combine\n",
        "matchingDf = pd.concat(matchingDfs)\n",
        "# Rename columns\n",
        "matchingDf.rename(columns = {\"Author_id\": \"author_id\", \"Disorder\": \"disorder\", \"Class\": \"group\"}, inplace = True)\n",
        "matchingDf[\"author_id\"] = matchingDf[\"author_id\"].astype(\"str\")\n",
        "\n",
        "# Drop the columns which are not needed\n",
        "matchingDf.drop([\"Feature_Vector\", \"Propensity_Score\"], axis = 1, inplace = True)\n",
        "\n",
        "# Reset the index\n",
        "matchingDf.reset_index(drop = True, inplace = True)\n",
        "\n",
        "# Check\n",
        "print(\"Resulting shape:\", matchingDf.shape)\n",
        "matchingDf.groupby([\"disorder\", \"group\"])[\"author_id\"].count().reset_index().pivot(index = \"disorder\", columns = \"group\", values = \"author_id\")"
      ],
      "metadata": {
        "id": "j5wi7K-_LTrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the stratum and the corrected disorder to the usersDf\n",
        "usersDf = usersDf.merge(matchingDf[[\"author_id\", \"disorder\", \"stratum\"]], on = [\"author_id\"], how = \"left\")\n",
        "# Drop the na based on stratum\n",
        "usersDf.dropna(subset = [\"stratum\"], inplace = True)\n",
        "# Convert the stratum to int\n",
        "usersDf[\"stratum\"] = usersDf[\"stratum\"].astype(\"int64\")\n",
        "# Check\n",
        "print(\"Shape after adding the matching info\", usersDf.shape)\n",
        "usersDf.groupby([\"disorder\", \"group\"])[\"author_id\"].count().reset_index().pivot(index = \"disorder\", columns = \"group\", values = \"author_id\")"
      ],
      "metadata": {
        "id": "AO-TrQRXLas-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the user info to tweetsDf, along with the corrected disorder\n",
        "if set([\"author_since\", \"stratum\"]).issubset(set(tweetsDf.columns)):\n",
        "  # drop\n",
        "  tweetsDf.drop(columns = [\"author_since\", \"stratum\"], inplace = True)\n",
        "# Update\n",
        "tweetsDf = tweetsDf.merge(usersDf[[\"author_id\", \"author_since\", \"disorder\", \"stratum\"]], on = [\"author_id\"], how = \"left\")\n",
        "# Rename the disorder column\n",
        "tweetsDf.rename(columns = {\"disorder_x\": \"orig_disorder\", \"disorder_y\": \"corrected_disorder\"}, inplace = True)\n",
        "# Fill the na corrected_disorder using orig_disorder\n",
        "tweetsDf[\"corrected_disorder\"] = tweetsDf[\"corrected_disorder\"].fillna(tweetsDf[\"orig_disorder\"])\n",
        "# Rename corrected_disorder and drop orig_disorder\n",
        "tweetsDf.rename(columns = {\"corrected_disorder\": \"disorder\"}, inplace = True)\n",
        "tweetsDf.drop(columns = [\"orig_disorder\"], inplace = True)\n",
        "\n",
        "# Check\n",
        "print(\"Shape after adding the user info\", tweetsDf.shape)\n",
        "tweetsDf.sample()"
      ],
      "metadata": {
        "id": "4JKl5VgeL1U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Validate"
      ],
      "metadata": {
        "id": "aWZK7UIGvuwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the users with different disorders on the usersDf and matchingDf\n",
        "mismatchedDisordersDf = matchingDf.merge(usersDf[[\"author_id\", \"disorder\"]], on = [\"author_id\"], how = \"inner\")\n",
        "mismatchedDisordersDf = mismatchedDisordersDf[mismatchedDisordersDf.disorder_x != mismatchedDisordersDf.disorder_y]\n",
        "mismatchedDisordersDf.rename(columns = {\"disorder_x\": \"disorder_matching\", \"disorder_y\": \"disorder_original\"}, inplace = True)\n",
        "print(\"Shape:\", mismatchedDisordersDf.shape)\n",
        "mismatchedDisordersDf.head(1)"
      ],
      "metadata": {
        "id": "GAxVnnHdvt7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mismatch dataset\n",
        "mismatchedDisordersDf.merge(tweetsDf[tweetsDf.author_id.isin(mismatchedDisordersDf.author_id)].groupby([\"author_id\"])[\"disorder\"].agg(pd.Series.mode).reset_index().rename(columns = {\"disorder\": \"disorder_tweets\"}), on = \"author_id\", how = \"left\")"
      ],
      "metadata": {
        "id": "Nw5WaTy8v1t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrectDisordersDf = tweetsDf.groupby(by = [\"author_id\"])[\"disorder\"].nunique().reset_index().query(\"disorder > 1\").reset_index(drop = True)\n",
        "print(\"Shape:\", incorrectDisordersDf.shape)\n",
        "incorrectDisordersDf.head(1)"
      ],
      "metadata": {
        "id": "oCc0Glryvdwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the above\n",
        "tweetsDf[tweetsDf.author_id.isin(incorrectDisordersDf.author_id)].stratum.notna().sum()"
      ],
      "metadata": {
        "id": "j_7PWYUaxgqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if authors in mismatchedDisordersDf are subset of incorrectDisordersDf\n",
        "incorrectDisordersDf[incorrectDisordersDf.author_id.isin(mismatchedDisordersDf.author_id)].shape"
      ],
      "metadata": {
        "id": "gDEJcCMnqPX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save users"
      ],
      "metadata": {
        "id": "5iaod5c6OMN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the users to parquet\n",
        "fileName = os.path.join(authorsDir, \"Authors.parquet\")\n",
        "usersDf.to_parquet(fileName)"
      ],
      "metadata": {
        "id": "Wj4pGoiXOLok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usersDf.groupby([\"disorder\", \"group\"])[\"author_id\"].count().reset_index().pivot(index = \"disorder\", columns = \"group\", values = \"author_id\")"
      ],
      "metadata": {
        "id": "XyltD7iUMiEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Touches"
      ],
      "metadata": {
        "id": "tqpJ66wmOVeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweetsDf.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "qUHlYq3auJEi",
        "outputId": "2542a7f2-57e9-4e85-8f40-5774e065b064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           id tweet_type referenced_tweet_type  \\\n",
              "12601561  1328498608019099648   timeline            replied_to   \n",
              "\n",
              "                  created_at lang author_id  \\\n",
              "12601561 2020-11-17 00:42:05   en  24323669   \n",
              "\n",
              "                                                       text  \\\n",
              "12601561  @melissita1 @RawBeautyKristi It saved my best ...   \n",
              "\n",
              "                            cleaned_text  retweet_count  reply_count  ...  \\\n",
              "12601561  it saved my best friends baby.              0            0  ...   \n",
              "\n",
              "          stress_score_org  relax_score stress_score  combined_score  \\\n",
              "12601561              -1.0          1.0          0.0           0.375   \n",
              "\n",
              "         age_group gender  edu_level  author_since    disorder  stratum  \n",
              "12601561      None   None       None           NaT  depression      NaN  \n",
              "\n",
              "[1 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc7d6626-3e5a-421c-bf1b-9c002b57cbaf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet_type</th>\n",
              "      <th>referenced_tweet_type</th>\n",
              "      <th>created_at</th>\n",
              "      <th>lang</th>\n",
              "      <th>author_id</th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>...</th>\n",
              "      <th>stress_score_org</th>\n",
              "      <th>relax_score</th>\n",
              "      <th>stress_score</th>\n",
              "      <th>combined_score</th>\n",
              "      <th>age_group</th>\n",
              "      <th>gender</th>\n",
              "      <th>edu_level</th>\n",
              "      <th>author_since</th>\n",
              "      <th>disorder</th>\n",
              "      <th>stratum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12601561</th>\n",
              "      <td>1328498608019099648</td>\n",
              "      <td>timeline</td>\n",
              "      <td>replied_to</td>\n",
              "      <td>2020-11-17 00:42:05</td>\n",
              "      <td>en</td>\n",
              "      <td>24323669</td>\n",
              "      <td>@melissita1 @RawBeautyKristi It saved my best ...</td>\n",
              "      <td>it saved my best friends baby.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.375</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "      <td>depression</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc7d6626-3e5a-421c-bf1b-9c002b57cbaf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc7d6626-3e5a-421c-bf1b-9c002b57cbaf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc7d6626-3e5a-421c-bf1b-9c002b57cbaf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweetsDf.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "LJDNUxGAZDPB",
        "outputId": "1b00d46d-6799-49fe-c6e8-9a7ed6c8fb2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                                int64\n",
              "tweet_type                       object\n",
              "referenced_tweet_type            object\n",
              "created_at               datetime64[ns]\n",
              "lang                             object\n",
              "author_id                        object\n",
              "text                             object\n",
              "cleaned_text                     object\n",
              "retweet_count                     int64\n",
              "reply_count                       int64\n",
              "like_count                        int64\n",
              "quote_count                       int64\n",
              "source                           object\n",
              "group                             int64\n",
              "diagnosis_date           datetime64[ns]\n",
              "treatment_date           datetime64[ns]\n",
              "music_id                        float64\n",
              "relax_score_org                 float64\n",
              "stress_score_org                float64\n",
              "relax_score                     float64\n",
              "stress_score                    float64\n",
              "combined_score                  float64\n",
              "age_group                        object\n",
              "gender                           object\n",
              "edu_level                        object\n",
              "author_since             datetime64[ns]\n",
              "disorder                         object\n",
              "stratum                         float64\n",
              "dtype: object"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweet_type</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>referenced_tweet_type</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>created_at</th>\n",
              "      <td>datetime64[ns]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lang</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>author_id</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cleaned_text</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retweet_count</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reply_count</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>like_count</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quote_count</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>group</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diagnosis_date</th>\n",
              "      <td>datetime64[ns]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>treatment_date</th>\n",
              "      <td>datetime64[ns]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>music_id</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relax_score_org</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stress_score_org</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relax_score</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stress_score</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>combined_score</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age_group</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>edu_level</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>author_since</th>\n",
              "      <td>datetime64[ns]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disorder</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stratum</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final data types fixes\n",
        "tweetsDf[\"diagnosis_date\"] = pd.to_datetime(tweetsDf[\"diagnosis_date\"])\n",
        "# Fill na on referenced_tweet_type\n",
        "tweetsDf[\"referenced_tweet_type\"] = tweetsDf[\"referenced_tweet_type\"].fillna(\"original\")"
      ],
      "metadata": {
        "id": "qA5NdZQqb3lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweetsDf.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98OlmlQsxDWv",
        "outputId": "519ce9f3-a3c2-409d-8ded-8a6013f17b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'tweet_type', 'referenced_tweet_type', 'created_at', 'lang',\n",
              "       'author_id', 'text', 'cleaned_text', 'retweet_count', 'reply_count',\n",
              "       'like_count', 'quote_count', 'source', 'group', 'diagnosis_date',\n",
              "       'treatment_date', 'music_id', 'relax_score_org', 'stress_score_org',\n",
              "       'relax_score', 'stress_score', 'combined_score', 'age_group', 'gender',\n",
              "       'edu_level', 'author_since', 'disorder', 'stratum'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reorganize the columns\n",
        "cols = ['id', 'tweet_type', 'referenced_tweet_type', 'created_at', 'lang',\n",
        "       'disorder', 'author_id', 'author_since', 'text', 'cleaned_text', 'retweet_count',\n",
        "       'reply_count', 'like_count', 'quote_count', 'source', 'group', 'stratum',\n",
        "       'diagnosis_date', 'treatment_date', 'music_id', 'relax_score_org',\n",
        "       'stress_score_org', 'relax_score', 'stress_score', 'combined_score',\n",
        "       'age_group', 'gender', 'edu_level']\n",
        "tweetsDf = tweetsDf[cols]"
      ],
      "metadata": {
        "id": "f5DOynMkPaDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check -- output number should be equal to the PSM # of users\n",
        "tweetsDf[tweetsDf.stratum.notna()].author_id.nunique()"
      ],
      "metadata": {
        "id": "zDB7aP9wN3_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save\n",
        "Main and individual disorder files"
      ],
      "metadata": {
        "id": "viuS4ygdOXpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the main dataframe to parquet\n",
        "fileName = os.path.join(tweetsDir, \"processedTweets.parquet\")\n",
        "tweetsDf.to_parquet(fileName)"
      ],
      "metadata": {
        "id": "kgzU-_T0EC-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the anxiety data with Tensi Score\n",
        "anxietyWithTensiScoreDf = tweetsDf[(tweetsDf.disorder == \"anxiety\")].drop_duplicates()\n",
        "fileName = os.path.join(tensiStrenghtDir, \"anxietyFullWithTensiScore.pickle\")\n",
        "anxietyWithTensiScoreDf.to_pickle(fileName)\n",
        "print(\"Shape:\", anxietyWithTensiScoreDf.shape)"
      ],
      "metadata": {
        "id": "BfdZaeWusXQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a5cffe-21a1-43ae-d5cf-76c2d7e344e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (3346488, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the depression data with Tensi Score\n",
        "depressionWithTensiScoreDf = tweetsDf[(tweetsDf.disorder == \"depression\")].drop_duplicates()\n",
        "fileName = os.path.join(tensiStrenghtDir, \"depressionFullWithTensiScore.pickle\")\n",
        "depressionWithTensiScoreDf.to_pickle(fileName)\n",
        "print(\"Shape:\", depressionWithTensiScoreDf.shape)"
      ],
      "metadata": {
        "id": "2fsYvvk_sp7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67ed299-b297-4ca3-cca1-3532d794dce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (7208458, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the PTSD data with Tensi Score\n",
        "ptsdWithTensiScoreDf = tweetsDf[(tweetsDf.disorder == \"ptsd\")].drop_duplicates()\n",
        "fileName = os.path.join(tensiStrenghtDir, \"ptsdFullWithTensiScore.pickle\")\n",
        "ptsdWithTensiScoreDf.to_pickle(fileName)\n",
        "print(\"Shape:\", ptsdWithTensiScoreDf.shape)"
      ],
      "metadata": {
        "id": "TTmaPcqvPtd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b33b541-faf0-4276-8167-628b05ed6f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (2967408, 28)\n"
          ]
        }
      ]
    }
  ]
}